{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd603644",
   "metadata": {},
   "source": [
    "# ðŸ§  Model Training: From Easy to Super Advanced\n",
    "\n",
    "**A Complete Journey Through Computer Vision Model Training**\n",
    "\n",
    "This notebook takes you from the most basic model training concepts to the cutting-edge, super-advanced techniques used in research and production systems.\n",
    "\n",
    "## ðŸ“š What You'll Learn\n",
    "\n",
    "### ðŸŒ± **Beginner Level (Easy)**\n",
    "- Simple linear classifiers\n",
    "- Basic neural networks with PyTorch\n",
    "- Transfer learning with pre-trained models\n",
    "- Basic data augmentation\n",
    "\n",
    "### ðŸš€ **Intermediate Level**\n",
    "- Custom CNN architectures\n",
    "- Advanced data augmentation\n",
    "- Learning rate scheduling\n",
    "- Model ensembling\n",
    "\n",
    "### âš¡ **Advanced Level**\n",
    "- Custom loss functions and optimizers\n",
    "- Multi-GPU training\n",
    "- Mixed precision training\n",
    "- Model compression and pruning\n",
    "\n",
    "### ðŸ”¬ **Super Advanced Level (Research-Grade)**\n",
    "- Neural Architecture Search (NAS)\n",
    "- Meta-learning and few-shot learning\n",
    "- Self-supervised learning\n",
    "- Adversarial training and robustness\n",
    "- Federated learning\n",
    "- Gradient accumulation and large batch training\n",
    "- Custom CUDA kernels integration\n",
    "- Distributed training across multiple nodes\n",
    "\n",
    "---\n",
    "\n",
    "**âš ï¸ Requirements:**\n",
    "- PyTorch 2.0+\n",
    "- CUDA-capable GPU (recommended)\n",
    "- 16GB+ RAM for advanced sections\n",
    "- Multiple GPUs for super-advanced distributed training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0611c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸ”§ Complete Setup: All Libraries for Easy to Super Advanced Training\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.amp import autocast, GradScaler  # Mixed precision\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import *\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "# Core libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Advanced libraries\n",
    "import timm  # PyTorch Image Models - state-of-the-art architectures\n",
    "import albumentations as A  # Advanced augmentations\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import optuna  # Hyperparameter optimization\n",
    "import wandb  # Experiment tracking\n",
    "\n",
    "# Super advanced libraries\n",
    "try:\n",
    "    import pytorch_lightning as pl  # High-level PyTorch wrapper\n",
    "    from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "    from pytorch_lightning.loggers import WandbLogger\n",
    "except ImportError:\n",
    "    print(\"âš ï¸  PyTorch Lightning not installed - some super advanced features will be unavailable\")\n",
    "\n",
    "try:\n",
    "    import higher  # Meta-learning\n",
    "except ImportError:\n",
    "    print(\"âš ï¸  Higher not installed - meta-learning examples will use manual implementation\")\n",
    "\n",
    "try:\n",
    "    from nni.compression.pytorch import ModelSpeedup\n",
    "    from nni.compression.pytorch.pruning import L1FilterPruner\n",
    "except ImportError:\n",
    "    print(\"âš ï¸  NNI not installed - model compression examples will use manual implementation\")\n",
    "\n",
    "# Scientific computing\n",
    "import scipy\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "# Set device and check capabilities\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ðŸ–¥ï¸  Device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"ðŸ”¥ GPU: {torch.cuda.get_device_name()}\")\n",
    "    print(f\"ðŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory // 1024**3} GB\")\n",
    "    print(f\"ðŸ”¢ CUDA Compute Capability: {torch.cuda.get_device_capability()}\")\n",
    "    print(f\"ðŸš€ Mixed Precision Support: {torch.cuda.is_bf16_supported()}\")\n",
    "\n",
    "# Multi-GPU setup\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"ðŸ”¥ Multiple GPUs detected: {torch.cuda.device_count()}\")\n",
    "    print(\"âœ… Ready for advanced multi-GPU training\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_seed(42)\n",
    "print(\"âœ… All libraries imported and environment configured!\")\n",
    "print(\"ðŸŽ¯ Ready for Easy to Super Advanced model training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd3befa",
   "metadata": {},
   "source": [
    "# ðŸŒ± Level 1: Easy - Basic Model Training\n",
    "\n",
    "Let's start with the absolute basics. We'll create simple datasets and train basic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bb1f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EasyTraining:\n",
    "    \"\"\"\n",
    "    Level 1: Easy model training for beginners\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.device = device\n",
    "        \n",
    "    def create_simple_dataset(self):\n",
    "        \"\"\"Create a simple synthetic dataset for learning\"\"\"\n",
    "        print(\"ðŸ“Š Creating Simple Synthetic Dataset\")\n",
    "        print(\"=\" * 38)\n",
    "        \n",
    "        # Create simple 2D classification data\n",
    "        np.random.seed(42)\n",
    "        n_samples = 1000\n",
    "        \n",
    "        # Class 0: circles\n",
    "        angles = np.random.uniform(0, 2*np.pi, n_samples//2)\n",
    "        radius = np.random.uniform(1, 3, n_samples//2)\n",
    "        x1 = radius * np.cos(angles) + np.random.normal(0, 0.3, n_samples//2)\n",
    "        y1 = radius * np.sin(angles) + np.random.normal(0, 0.3, n_samples//2)\n",
    "        \n",
    "        # Class 1: diagonal line\n",
    "        x2 = np.random.uniform(-5, 5, n_samples//2)\n",
    "        y2 = x2 + np.random.normal(0, 0.5, n_samples//2)\n",
    "        \n",
    "        # Combine data\n",
    "        X = np.vstack([np.column_stack([x1, y1]), np.column_stack([x2, y2])])\n",
    "        y = np.hstack([np.zeros(n_samples//2), np.ones(n_samples//2)])\n",
    "        \n",
    "        # Visualize\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        scatter = plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', alpha=0.7)\n",
    "        plt.colorbar(scatter)\n",
    "        plt.title('Simple 2D Classification Dataset')\n",
    "        plt.xlabel('Feature 1')\n",
    "        plt.ylabel('Feature 2')\n",
    "        plt.show()\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        X_tensor = torch.FloatTensor(X).to(self.device)\n",
    "        y_tensor = torch.LongTensor(y).to(self.device)\n",
    "        \n",
    "        print(f\"âœ… Dataset created: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "        return X_tensor, y_tensor\n",
    "    \n",
    "    def simple_neural_network(self, input_size=2, hidden_size=64, num_classes=2):\n",
    "        \"\"\"Create a simple feedforward neural network\"\"\"\n",
    "        print(\"ðŸ§  Creating Simple Neural Network\")\n",
    "        print(\"=\" * 32)\n",
    "        \n",
    "        class SimpleNN(nn.Module):\n",
    "            def __init__(self, input_size, hidden_size, num_classes):\n",
    "                super(SimpleNN, self).__init__()\n",
    "                self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "                self.relu = nn.ReLU()\n",
    "                self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "                self.fc3 = nn.Linear(hidden_size, num_classes)\n",
    "                self.dropout = nn.Dropout(0.2)\n",
    "                \n",
    "            def forward(self, x):\n",
    "                x = self.fc1(x)\n",
    "                x = self.relu(x)\n",
    "                x = self.dropout(x)\n",
    "                x = self.fc2(x)\n",
    "                x = self.relu(x)\n",
    "                x = self.dropout(x)\n",
    "                x = self.fc3(x)\n",
    "                return x\n",
    "        \n",
    "        model = SimpleNN(input_size, hidden_size, num_classes).to(self.device)\n",
    "        \n",
    "        # Print model architecture\n",
    "        print(f\"Model Architecture:\")\n",
    "        print(model)\n",
    "        \n",
    "        # Count parameters\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(f\"\\nðŸ“Š Total parameters: {total_params:,}\")\n",
    "        print(f\"ðŸ“Š Trainable parameters: {trainable_params:,}\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def basic_training_loop(self, model, X, y, epochs=100, lr=0.001):\n",
    "        \"\"\"Basic training loop with visualization\"\"\"\n",
    "        print(\"ðŸƒ Starting Basic Training Loop\")\n",
    "        print(\"=\" * 30)\n",
    "        \n",
    "        # Split data\n",
    "        n_train = int(0.8 * len(X))\n",
    "        indices = torch.randperm(len(X))\n",
    "        train_indices, val_indices = indices[:n_train], indices[n_train:]\n",
    "        \n",
    "        X_train, X_val = X[train_indices], X[val_indices]\n",
    "        y_train, y_val = y[train_indices], y[val_indices]\n",
    "        \n",
    "        # Loss and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        # Training history\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        train_accs = []\n",
    "        val_accs = []\n",
    "        \n",
    "        print(f\"Training on {len(X_train)} samples, validating on {len(X_val)} samples\")\n",
    "        \n",
    "        # Training loop\n",
    "        for epoch in range(epochs):\n",
    "            # Training\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(X_train)\n",
    "            loss = criterion(outputs, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Calculate training accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            train_acc = (predicted == y_train).float().mean().item()\n",
    "            \n",
    "            # Validation\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_outputs = model(X_val)\n",
    "                val_loss = criterion(val_outputs, y_val)\n",
    "                _, val_predicted = torch.max(val_outputs.data, 1)\n",
    "                val_acc = (val_predicted == y_val).float().mean().item()\n",
    "            \n",
    "            # Store history\n",
    "            train_losses.append(loss.item())\n",
    "            val_losses.append(val_loss.item())\n",
    "            train_accs.append(train_acc)\n",
    "            val_accs.append(val_acc)\n",
    "            \n",
    "            # Print progress\n",
    "            if (epoch + 1) % 20 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}] - \"\n",
    "                      f\"Train Loss: {loss.item():.4f}, Train Acc: {train_acc:.4f} - \"\n",
    "                      f\"Val Loss: {val_loss.item():.4f}, Val Acc: {val_acc:.4f}\")\n",
    "        \n",
    "        # Plot training history\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        \n",
    "        # Loss plot\n",
    "        ax1.plot(train_losses, label='Training Loss', color='blue')\n",
    "        ax1.plot(val_losses, label='Validation Loss', color='red')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.set_title('Training and Validation Loss')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True)\n",
    "        \n",
    "        # Accuracy plot\n",
    "        ax2.plot(train_accs, label='Training Accuracy', color='blue')\n",
    "        ax2.plot(val_accs, label='Validation Accuracy', color='red')\n",
    "        ax2.set_xlabel('Epoch')\n",
    "        ax2.set_ylabel('Accuracy')\n",
    "        ax2.set_title('Training and Validation Accuracy')\n",
    "        ax2.legend()\n",
    "        ax2.grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"\\nâœ… Training completed!\")\n",
    "        print(f\"ðŸ“Š Final Training Accuracy: {train_accs[-1]:.4f}\")\n",
    "        print(f\"ðŸ“Š Final Validation Accuracy: {val_accs[-1]:.4f}\")\n",
    "        \n",
    "        return model, (train_losses, val_losses, train_accs, val_accs)\n",
    "\n",
    "# Create instance\n",
    "easy_trainer = EasyTraining()\n",
    "print(\"ðŸŒ± Easy Training module initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47382554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ¯ RUN EASY TRAINING DEMO\n",
    "print(\"ðŸš€ RUNNING EASY TRAINING DEMONSTRATION\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create dataset\n",
    "X, y = easy_trainer.create_simple_dataset()\n",
    "\n",
    "# Create model\n",
    "simple_model = easy_trainer.simple_neural_network()\n",
    "\n",
    "# Train model\n",
    "trained_model, history = easy_trainer.basic_training_loop(simple_model, X, y, epochs=100)\n",
    "\n",
    "print(\"\\nðŸŽ‰ Easy training demonstration completed!\")\n",
    "print(\"ðŸ’¡ You've successfully trained your first neural network!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5bd1e9",
   "metadata": {},
   "source": [
    "# ðŸš€ Level 2: Intermediate - Image Classification with CNNs\n",
    "\n",
    "Now let's move to image data and convolutional neural networks with more advanced techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb501d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntermediateTraining:\n",
    "    \"\"\"\n",
    "    Level 2: Intermediate training with CNNs and real image data\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.device = device\n",
    "        \n",
    "    def create_real_world_dataset(self):\n",
    "        \"\"\"Create or load a real-world image dataset\"\"\"\n",
    "        print(\"ðŸ“¸ Creating Real-World Image Dataset\")\n",
    "        print(\"=\" * 37)\n",
    "        \n",
    "        # Download CIFAR-10 dataset\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        ])\n",
    "        \n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "        ])\n",
    "        \n",
    "        print(\"ðŸ“¥ Downloading CIFAR-10 dataset...\")\n",
    "        trainset = torchvision.datasets.CIFAR10(\n",
    "            root='./data', train=True, download=True, transform=transform_train)\n",
    "        testset = torchvision.datasets.CIFAR10(\n",
    "            root='./data', train=False, download=True, transform=transform_test)\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_loader = DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "        test_loader = DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "        \n",
    "        # CIFAR-10 classes\n",
    "        classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "        \n",
    "        print(f\"âœ… Dataset loaded: {len(trainset)} training, {len(testset)} test samples\")\n",
    "        print(f\"ðŸ“Š Classes: {classes}\")\n",
    "        \n",
    "        # Visualize some samples\n",
    "        self.visualize_dataset(train_loader, classes)\n",
    "        \n",
    "        return train_loader, test_loader, classes\n",
    "    \n",
    "    def visualize_dataset(self, dataloader, classes):\n",
    "        \"\"\"Visualize dataset samples\"\"\"\n",
    "        # Get one batch\n",
    "        dataiter = iter(dataloader)\n",
    "        images, labels = next(dataiter)\n",
    "        \n",
    "        # Denormalize for visualization\n",
    "        mean = torch.tensor([0.4914, 0.4822, 0.4465]).view(3, 1, 1)\n",
    "        std = torch.tensor([0.2023, 0.1994, 0.2010]).view(3, 1, 1)\n",
    "        images = images * std + mean\n",
    "        images = torch.clamp(images, 0, 1)\n",
    "        \n",
    "        # Plot samples\n",
    "        fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "        for i in range(16):\n",
    "            row, col = i // 8, i % 8\n",
    "            axes[row, col].imshow(images[i].permute(1, 2, 0))\n",
    "            axes[row, col].set_title(f'{classes[labels[i]]}')\n",
    "            axes[row, col].axis('off')\n",
    "        \n",
    "        plt.suptitle('CIFAR-10 Dataset Samples')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def create_custom_cnn(self, num_classes=10):\n",
    "        \"\"\"Create a custom CNN architecture\"\"\"\n",
    "        print(\"ðŸ—ï¸  Creating Custom CNN Architecture\")\n",
    "        print(\"=\" * 35)\n",
    "        \n",
    "        class CustomCNN(nn.Module):\n",
    "            def __init__(self, num_classes=10):\n",
    "                super(CustomCNN, self).__init__()\n",
    "                \n",
    "                # Convolutional layers\n",
    "                self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "                self.bn1 = nn.BatchNorm2d(64)\n",
    "                self.conv2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "                self.bn2 = nn.BatchNorm2d(64)\n",
    "                \n",
    "                self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "                self.bn3 = nn.BatchNorm2d(128)\n",
    "                self.conv4 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "                self.bn4 = nn.BatchNorm2d(128)\n",
    "                \n",
    "                self.conv5 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "                self.bn5 = nn.BatchNorm2d(256)\n",
    "                self.conv6 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "                self.bn6 = nn.BatchNorm2d(256)\n",
    "                \n",
    "                # Pooling and dropout\n",
    "                self.pool = nn.MaxPool2d(2, 2)\n",
    "                self.dropout = nn.Dropout(0.5)\n",
    "                self.dropout_conv = nn.Dropout2d(0.25)\n",
    "                \n",
    "                # Fully connected layers\n",
    "                self.fc1 = nn.Linear(256 * 4 * 4, 512)\n",
    "                self.fc2 = nn.Linear(512, 256)\n",
    "                self.fc3 = nn.Linear(256, num_classes)\n",
    "                \n",
    "                # Activation functions\n",
    "                self.relu = nn.ReLU(inplace=True)\n",
    "                \n",
    "            def forward(self, x):\n",
    "                # Block 1\n",
    "                x = self.relu(self.bn1(self.conv1(x)))\n",
    "                x = self.relu(self.bn2(self.conv2(x)))\n",
    "                x = self.pool(x)\n",
    "                x = self.dropout_conv(x)\n",
    "                \n",
    "                # Block 2\n",
    "                x = self.relu(self.bn3(self.conv3(x)))\n",
    "                x = self.relu(self.bn4(self.conv4(x)))\n",
    "                x = self.pool(x)\n",
    "                x = self.dropout_conv(x)\n",
    "                \n",
    "                # Block 3\n",
    "                x = self.relu(self.bn5(self.conv5(x)))\n",
    "                x = self.relu(self.bn6(self.conv6(x)))\n",
    "                x = self.pool(x)\n",
    "                x = self.dropout_conv(x)\n",
    "                \n",
    "                # Classifier\n",
    "                x = x.view(-1, 256 * 4 * 4)\n",
    "                x = self.relu(self.fc1(x))\n",
    "                x = self.dropout(x)\n",
    "                x = self.relu(self.fc2(x))\n",
    "                x = self.dropout(x)\n",
    "                x = self.fc3(x)\n",
    "                \n",
    "                return x\n",
    "        \n",
    "        model = CustomCNN(num_classes).to(self.device)\n",
    "        \n",
    "        # Print model info\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        \n",
    "        print(f\"ðŸ“Š Total parameters: {total_params:,}\")\n",
    "        print(f\"ðŸ“Š Trainable parameters: {trainable_params:,}\")\n",
    "        \n",
    "        # Calculate model size\n",
    "        param_size = 0\n",
    "        for param in model.parameters():\n",
    "            param_size += param.nelement() * param.element_size()\n",
    "        buffer_size = 0\n",
    "        for buffer in model.buffers():\n",
    "            buffer_size += buffer.nelement() * buffer.element_size()\n",
    "        model_size = (param_size + buffer_size) / 1024 / 1024\n",
    "        print(f\"ðŸ“Š Model size: {model_size:.2f} MB\")\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    def advanced_training_loop(self, model, train_loader, test_loader, epochs=50):\n",
    "        \"\"\"Advanced training with scheduling and monitoring\"\"\"\n",
    "        print(\"ðŸƒ Starting Advanced Training Loop\")\n",
    "        print(\"=\" * 33)\n",
    "        \n",
    "        # Loss and optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "        \n",
    "        # Learning rate scheduler\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "        \n",
    "        # Training history\n",
    "        history = {\n",
    "            'train_loss': [], 'train_acc': [],\n",
    "            'test_loss': [], 'test_acc': [],\n",
    "            'lr': []\n",
    "        }\n",
    "        \n",
    "        best_acc = 0.0\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            train_correct = 0\n",
    "            train_total = 0\n",
    "            \n",
    "            progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')\n",
    "            \n",
    "            for batch_idx, (data, target) in enumerate(progress_bar):\n",
    "                data, target = data.to(self.device), target.to(self.device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                # Statistics\n",
    "                train_loss += loss.item()\n",
    "                _, predicted = output.max(1)\n",
    "                train_total += target.size(0)\n",
    "                train_correct += predicted.eq(target).sum().item()\n",
    "                \n",
    "                # Update progress bar\n",
    "                progress_bar.set_postfix({\n",
    "                    'Loss': f'{loss.item():.4f}',\n",
    "                    'Acc': f'{100.*train_correct/train_total:.2f}%'\n",
    "                })\n",
    "            \n",
    "            # Testing phase\n",
    "            model.eval()\n",
    "            test_loss = 0.0\n",
    "            test_correct = 0\n",
    "            test_total = 0\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for data, target in test_loader:\n",
    "                    data, target = data.to(self.device), target.to(self.device)\n",
    "                    output = model(data)\n",
    "                    test_loss += criterion(output, target).item()\n",
    "                    \n",
    "                    _, predicted = output.max(1)\n",
    "                    test_total += target.size(0)\n",
    "                    test_correct += predicted.eq(target).sum().item()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            train_loss /= len(train_loader)\n",
    "            train_acc = 100. * train_correct / train_total\n",
    "            test_loss /= len(test_loader)\n",
    "            test_acc = 100. * test_correct / test_total\n",
    "            \n",
    "            # Update learning rate\n",
    "            scheduler.step()\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            # Store history\n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['train_acc'].append(train_acc)\n",
    "            history['test_loss'].append(test_loss)\n",
    "            history['test_acc'].append(test_acc)\n",
    "            history['lr'].append(current_lr)\n",
    "            \n",
    "            # Save best model\n",
    "            if test_acc > best_acc:\n",
    "                best_acc = test_acc\n",
    "                torch.save(model.state_dict(), 'best_model.pth')\n",
    "            \n",
    "            # Print epoch results\n",
    "            print(f'Epoch: {epoch+1:3d} | '\n",
    "                  f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | '\n",
    "                  f'Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}% | '\n",
    "                  f'LR: {current_lr:.6f}')\n",
    "        \n",
    "        print(f\"\\nâœ… Training completed! Best accuracy: {best_acc:.2f}%\")\n",
    "        \n",
    "        # Plot training history\n",
    "        self.plot_training_history(history)\n",
    "        \n",
    "        return model, history\n",
    "    \n",
    "    def plot_training_history(self, history):\n",
    "        \"\"\"Plot comprehensive training history\"\"\"\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        \n",
    "        # Loss plot\n",
    "        axes[0, 0].plot(history['train_loss'], label='Training Loss', color='blue')\n",
    "        axes[0, 0].plot(history['test_loss'], label='Test Loss', color='red')\n",
    "        axes[0, 0].set_xlabel('Epoch')\n",
    "        axes[0, 0].set_ylabel('Loss')\n",
    "        axes[0, 0].set_title('Training and Test Loss')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True)\n",
    "        \n",
    "        # Accuracy plot\n",
    "        axes[0, 1].plot(history['train_acc'], label='Training Accuracy', color='blue')\n",
    "        axes[0, 1].plot(history['test_acc'], label='Test Accuracy', color='red')\n",
    "        axes[0, 1].set_xlabel('Epoch')\n",
    "        axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "        axes[0, 1].set_title('Training and Test Accuracy')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True)\n",
    "        \n",
    "        # Learning rate plot\n",
    "        axes[1, 0].plot(history['lr'], color='green')\n",
    "        axes[1, 0].set_xlabel('Epoch')\n",
    "        axes[1, 0].set_ylabel('Learning Rate')\n",
    "        axes[1, 0].set_title('Learning Rate Schedule')\n",
    "        axes[1, 0].grid(True)\n",
    "        \n",
    "        # Overfitting analysis\n",
    "        gap = np.array(history['train_acc']) - np.array(history['test_acc'])\n",
    "        axes[1, 1].plot(gap, color='purple')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('Accuracy Gap (%)')\n",
    "        axes[1, 1].set_title('Overfitting Analysis (Train - Test Acc)')\n",
    "        axes[1, 1].grid(True)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Create instance\n",
    "intermediate_trainer = IntermediateTraining()\n",
    "print(\"ðŸš€ Intermediate Training module initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18428154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ¯ RUN INTERMEDIATE TRAINING DEMO\n",
    "print(\"ðŸš€ RUNNING INTERMEDIATE TRAINING DEMONSTRATION\")\n",
    "print(\"=\" * 46)\n",
    "\n",
    "# Create dataset\n",
    "train_loader, test_loader, classes = intermediate_trainer.create_real_world_dataset()\n",
    "\n",
    "# Create custom CNN\n",
    "cnn_model = intermediate_trainer.create_custom_cnn(num_classes=10)\n",
    "\n",
    "# Train with advanced techniques (reduce epochs for demo)\n",
    "print(\"\\nðŸƒ Starting advanced training (using fewer epochs for demonstration)...\")\n",
    "trained_cnn, cnn_history = intermediate_trainer.advanced_training_loop(\n",
    "    cnn_model, train_loader, test_loader, epochs=10\n",
    ")\n",
    "\n",
    "print(\"\\nðŸŽ‰ Intermediate training demonstration completed!\")\n",
    "print(\"ðŸ’¡ You've successfully trained a CNN with advanced techniques!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d253269a",
   "metadata": {},
   "source": [
    "# âš¡ Level 3: Advanced - Multi-GPU, Mixed Precision & Custom Components\n",
    "\n",
    "Now we enter the advanced realm with multi-GPU training, mixed precision, custom loss functions, and model optimization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b3db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdvancedTraining:\n",
    "    \"\"\"\n",
    "    Level 3: Advanced training with multi-GPU, mixed precision, and custom components\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.device = device\n",
    "        self.scaler = GradScaler()  # For mixed precision\n",
    "        \n",
    "    def custom_loss_functions(self):\n",
    "        \"\"\"Demonstrate custom loss function implementations\"\"\"\n",
    "        print(\"ðŸ”§ Custom Loss Functions\")\n",
    "        print(\"=\" * 24)\n",
    "        \n",
    "        class FocalLoss(nn.Module):\n",
    "            \"\"\"Focal Loss for addressing class imbalance\"\"\"\n",
    "            def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "                super(FocalLoss, self).__init__()\n",
    "                self.alpha = alpha\n",
    "                self.gamma = gamma\n",
    "                self.reduction = reduction\n",
    "                \n",
    "            def forward(self, inputs, targets):\n",
    "                ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "                pt = torch.exp(-ce_loss)\n",
    "                focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss\n",
    "                \n",
    "                if self.reduction == 'mean':\n",
    "                    return focal_loss.mean()\n",
    "                elif self.reduction == 'sum':\n",
    "                    return focal_loss.sum()\n",
    "                else:\n",
    "                    return focal_loss\n",
    "        \n",
    "        class LabelSmoothingLoss(nn.Module):\n",
    "            \"\"\"Label Smoothing for better generalization\"\"\"\n",
    "            def __init__(self, num_classes, smoothing=0.1):\n",
    "                super(LabelSmoothingLoss, self).__init__()\n",
    "                self.num_classes = num_classes\n",
    "                self.smoothing = smoothing\n",
    "                \n",
    "            def forward(self, inputs, targets):\n",
    "                log_probs = F.log_softmax(inputs, dim=1)\n",
    "                targets_one_hot = torch.zeros_like(log_probs)\n",
    "                targets_one_hot.fill_(self.smoothing / (self.num_classes - 1))\n",
    "                targets_one_hot.scatter_(1, targets.unsqueeze(1), 1.0 - self.smoothing)\n",
    "                \n",
    "                loss = (-targets_one_hot * log_probs).sum(dim=1).mean()\n",
    "                return loss\n",
    "        \n",
    "        class CutMixLoss(nn.Module):\n",
    "            \"\"\"CutMix loss for data augmentation\"\"\"\n",
    "            def __init__(self, criterion):\n",
    "                super(CutMixLoss, self).__init__()\n",
    "                self.criterion = criterion\n",
    "                \n",
    "            def forward(self, pred, y_a, y_b, lam):\n",
    "                return lam * self.criterion(pred, y_a) + (1 - lam) * self.criterion(pred, y_b)\n",
    "        \n",
    "        print(\"âœ… Custom loss functions defined:\")\n",
    "        print(\"   - Focal Loss: Handles class imbalance\")\n",
    "        print(\"   - Label Smoothing: Improves generalization\")\n",
    "        print(\"   - CutMix Loss: Advanced data augmentation\")\n",
    "        \n",
    "        return FocalLoss, LabelSmoothingLoss, CutMixLoss\n",
    "    \n",
    "    def mixed_precision_training(self, model, train_loader, test_loader, epochs=20):\n",
    "        \"\"\"Training with Automatic Mixed Precision (AMP)\"\"\"\n",
    "        print(\"ðŸš€ Mixed Precision Training\")\n",
    "        print(\"=\" * 26)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "        scheduler = optim.lr_scheduler.OneCycleLR(\n",
    "            optimizer, max_lr=0.01, steps_per_epoch=len(train_loader), epochs=epochs\n",
    "        )\\n        \n",
    "        history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}\\n        best_acc = 0.0\\n        \n",
    "        print(f\"ðŸ”¥ Training with Mixed Precision (FP16)...\")\n",
    "        \\n        for epoch in range(epochs):\\n            # Training phase\\n            model.train()\\n            train_loss = 0.0\\n            train_correct = 0\\n            train_total = 0\\n            \\n            progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} (AMP)')\\n            \\n            for batch_idx, (data, target) in enumerate(progress_bar):\\n                data, target = data.to(self.device), target.to(self.device)\\n                \\n                optimizer.zero_grad()\\n                \\n                # Mixed precision forward pass\\n                with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):\\n                    output = model(data)\\n                    loss = criterion(output, target)\\n                \\n                # Mixed precision backward pass\\n                self.scaler.scale(loss).backward()\\n                self.scaler.step(optimizer)\\n                self.scaler.update()\\n                scheduler.step()\\n                \\n                # Statistics\\n                train_loss += loss.item()\\n                _, predicted = output.max(1)\\n                train_total += target.size(0)\\n                train_correct += predicted.eq(target).sum().item()\\n                \\n                progress_bar.set_postfix({\\n                    'Loss': f'{loss.item():.4f}',\\n                    'Acc': f'{100.*train_correct/train_total:.2f}%',\\n                    'LR': f'{scheduler.get_last_lr()[0]:.6f}'\\n                })\\n            \\n            # Testing phase\\n            model.eval()\\n            test_loss = 0.0\\n            test_correct = 0\\n            test_total = 0\\n            \\n            with torch.no_grad():\\n                for data, target in test_loader:\\n                    data, target = data.to(self.device), target.to(self.device)\\n                    \\n                    with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):\\n                        output = model(data)\\n                        test_loss += criterion(output, target).item()\\n                    \\n                    _, predicted = output.max(1)\\n                    test_total += target.size(0)\\n                    test_correct += predicted.eq(target).sum().item()\\n            \\n            # Calculate metrics\\n            train_loss /= len(train_loader)\\n            train_acc = 100. * train_correct / train_total\\n            test_loss /= len(test_loader)\\n            test_acc = 100. * test_correct / test_total\\n            \\n            # Store history\\n            history['train_loss'].append(train_loss)\\n            history['train_acc'].append(train_acc)\\n            history['test_loss'].append(test_loss)\\n            history['test_acc'].append(test_acc)\\n            \\n            if test_acc > best_acc:\\n                best_acc = test_acc\\n                torch.save(model.state_dict(), 'best_model_amp.pth')\\n            \\n            print(f'Epoch: {epoch+1:3d} | '\\n                  f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | '\\n                  f'Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%')\\n        \\n        print(f\\\"\\\\nâœ… Mixed Precision Training completed! Best accuracy: {best_acc:.2f}%\\\")\\n        print(f\\\"ðŸ’¡ Mixed precision can provide 1.5-2x speedup with minimal accuracy loss\\\")\\n        \\n        return model, history\\n    \\n    def model_ensembling(self, models, test_loader):\\n        \\\"\\\"\\\"Demonstrate model ensembling techniques\\\"\\\"\\\"\\n        print(\\\"ðŸŽ­ Model Ensembling\\\")\\n        print(\\\"=\\\" * 17)\\n        \\n        def evaluate_ensemble(models, dataloader, ensemble_method='average'):\\n            \\\"\\\"\\\"Evaluate ensemble of models\\\"\\\"\\\"\\n            all_models_eval = [model.eval() for model in models]\\n            correct = 0\\n            total = 0\\n            \\n            with torch.no_grad():\\n                for data, target in dataloader:\\n                    data, target = data.to(self.device), target.to(self.device)\\n                    \\n                    # Get predictions from all models\\n                    predictions = []\\n                    for model in models:\\n                        with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):\\n                            output = model(data)\\n                            predictions.append(F.softmax(output, dim=1))\\n                    \\n                    # Ensemble predictions\\n                    if ensemble_method == 'average':\\n                        ensemble_pred = torch.stack(predictions).mean(dim=0)\\n                    elif ensemble_method == 'max':\\n                        ensemble_pred = torch.stack(predictions).max(dim=0)[0]\\n                    elif ensemble_method == 'weighted':\\n                        # Simple equal weighting - could be learned\\n                        weights = torch.ones(len(models)) / len(models)\\n                        ensemble_pred = sum(w * pred for w, pred in zip(weights, predictions))\\n                    \\n                    _, predicted = ensemble_pred.max(1)\\n                    total += target.size(0)\\n                    correct += predicted.eq(target).sum().item()\\n            \\n            return 100. * correct / total\\n        \\n        # Test different ensemble methods\\n        methods = ['average', 'max', 'weighted']\\n        results = {}\\n        \\n        for method in methods:\\n            acc = evaluate_ensemble(models, test_loader, method)\\n            results[method] = acc\\n            print(f\\\"ðŸ“Š {method.capitalize()} Ensemble Accuracy: {acc:.2f}%\\\")\\n        \\n        # Compare with individual models\\n        print(\\\"\\\\nðŸ“Š Individual Model Performance:\\\")\\n        for i, model in enumerate(models):\\n            individual_acc = evaluate_ensemble([model], test_loader)\\n            print(f\\\"   Model {i+1}: {individual_acc:.2f}%\\\")\\n        \\n        print(f\\\"\\\\nâœ… Best ensemble method: {max(results, key=results.get)} ({max(results.values()):.2f}%)\\\")\\n        \\n        return results\\n    \\n    def model_compression_pruning(self, model):\\n        \\\"\\\"\\\"Demonstrate model compression through pruning\\\"\\\"\\\"\\n        print(\\\"âœ‚ï¸  Model Compression & Pruning\\\")\\n        print(\\\"=\\\" * 29)\\n        \\n        import torch.nn.utils.prune as prune\\n        \\n        # Calculate original model size\\n        original_size = sum(p.numel() for p in model.parameters())\\n        \\n        # Global magnitude pruning\\n        parameters_to_prune = []\\n        for name, module in model.named_modules():\\n            if isinstance(module, (nn.Conv2d, nn.Linear)):\\n                parameters_to_prune.append((module, 'weight'))\\n        \\n        # Prune 20% of connections globally\\n        prune.global_unstructured(\\n            parameters_to_prune,\\n            pruning_method=prune.L1Unstructured,\\n            amount=0.2,\\n        )\\n        \\n        # Calculate compressed model size\\n        compressed_size = sum(p.numel() for p in model.parameters() if p.requires_grad)\\n        \\n        print(f\\\"ðŸ“Š Original model parameters: {original_size:,}\\\")\\n        print(f\\\"ðŸ“Š Compressed model parameters: {compressed_size:,}\\\")\\n        print(f\\\"ðŸ“Š Compression ratio: {original_size/compressed_size:.2f}x\\\")\\n        print(f\\\"ðŸ“Š Parameter reduction: {(1-compressed_size/original_size)*100:.1f}%\\\")\\n        \\n        # Remove pruning masks to make pruning permanent\\n        for module, param_name in parameters_to_prune:\\n            prune.remove(module, param_name)\\n        \\n        print(\\\"âœ… Model pruning completed!\\\")\\n        print(\\\"ðŸ’¡ Pruned models typically need fine-tuning to recover performance\\\")\\n        \\n        return model\\n    \\n    def gradient_accumulation_training(self, model, train_loader, test_loader, \\n                                      accumulation_steps=4, epochs=10):\\n        \\\"\\\"\\\"Training with gradient accumulation for large effective batch sizes\\\"\\\"\\\"\\n        print(f\\\"ðŸ”„ Gradient Accumulation Training\\\")\\n        print(f\\\"   Effective batch size: {train_loader.batch_size * accumulation_steps}\\\")\\n        print(\\\"=\\\" * 33)\\n        \\n        criterion = nn.CrossEntropyLoss()\\n        optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\\n        \\n        for epoch in range(epochs):\\n            model.train()\\n            running_loss = 0.0\\n            \\n            progress_bar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs} (GradAccum)')\\n            \\n            for batch_idx, (data, target) in enumerate(progress_bar):\\n                data, target = data.to(self.device), target.to(self.device)\\n                \\n                with autocast(device_type='cuda' if torch.cuda.is_available() else 'cpu'):\\n                    output = model(data)\\n                    loss = criterion(output, target) / accumulation_steps  # Scale loss\\n                \\n                self.scaler.scale(loss).backward()\\n                \\n                if (batch_idx + 1) % accumulation_steps == 0:\\n                    self.scaler.step(optimizer)\\n                    self.scaler.update()\\n                    optimizer.zero_grad()\\n                \\n                running_loss += loss.item() * accumulation_steps\\n                \\n                progress_bar.set_postfix({\\n                    'Loss': f'{running_loss/(batch_idx+1):.4f}',\\n                    'Step': f'{(batch_idx+1)//accumulation_steps}'\\n                })\\n            \\n            print(f'Epoch {epoch+1} completed - Avg Loss: {running_loss/len(train_loader):.4f}')\\n        \\n        print(\\\"âœ… Gradient accumulation training completed!\\\")\\n        print(\\\"ðŸ’¡ Allows training with larger effective batch sizes on limited GPU memory\\\")\\n        \\n        return model\n",
    "\n",
    "# Create instance\n",
    "advanced_trainer = AdvancedTraining()\n",
    "print(\"âš¡ Advanced Training module initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f28fd0",
   "metadata": {},
   "source": [
    "# ðŸ”¬ Level 4: Super Advanced - Research-Grade Techniques\n",
    "\n",
    "Welcome to the cutting edge! This section covers the most advanced techniques used in research and production at scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecd06b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperAdvancedTraining:\n",
    "    \"\"\"\n",
    "    Level 4: Super Advanced - Research-grade techniques\n",
    "    Including NAS, meta-learning, self-supervised learning, and distributed training\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.device = device\n",
    "        \n",
    "    def neural_architecture_search(self, search_space_size=50, epochs_per_architecture=5):\n",
    "        \"\"\"Simple Neural Architecture Search implementation\"\"\"\n",
    "        print(\"ðŸ” Neural Architecture Search (NAS)\")\n",
    "        print(\"=\" * 35)\n",
    "        \n",
    "        class SearchableConvBlock(nn.Module):\n",
    "            \\\"\\\"\\\"Searchable convolutional block with different options\\\"\\\"\\\"\\n            def __init__(self, in_channels, out_channels):\\n                super().__init__()\\n                # Different kernel sizes to search over\\n                self.conv3x3 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\\n                self.conv5x5 = nn.Conv2d(in_channels, out_channels, 5, padding=2)\\n                self.conv1x1 = nn.Conv2d(in_channels, out_channels, 1)\\n                self.bn = nn.BatchNorm2d(out_channels)\\n                self.relu = nn.ReLU(inplace=True)\\n                \\n            def forward(self, x, arch_choice):\\n                if arch_choice == 0:\\n                    x = self.conv3x3(x)\\n                elif arch_choice == 1:\\n                    x = self.conv5x5(x)\\n                else:\\n                    x = self.conv1x1(x)\\n                return self.relu(self.bn(x))\\n        \\n        class NASModel(nn.Module):\\n            \\\"\\\"\\\"Model with searchable architecture\\\"\\\"\\\"\\n            def __init__(self, num_classes=10):\\n                super().__init__()\\n                self.layer1 = SearchableConvBlock(3, 64)\\n                self.layer2 = SearchableConvBlock(64, 128)\\n                self.layer3 = SearchableConvBlock(128, 256)\\n                self.pool = nn.AdaptiveAvgPool2d(1)\\n                self.fc = nn.Linear(256, num_classes)\\n                \\n            def forward(self, x, architecture):\\n                x = self.layer1(x, architecture[0])\\n                x = F.max_pool2d(x, 2)\\n                x = self.layer2(x, architecture[1])\\n                x = F.max_pool2d(x, 2)\\n                x = self.layer3(x, architecture[2])\\n                x = self.pool(x)\\n                x = x.view(x.size(0), -1)\\n                x = self.fc(x)\\n                return x\\n        \\n        def evaluate_architecture(architecture, model, train_loader, test_loader):\\n            \\\"\\\"\\\"Evaluate a specific architecture\\\"\\\"\\\"\\n            criterion = nn.CrossEntropyLoss()\\n            optimizer = optim.Adam(model.parameters(), lr=0.001)\\n            \\n            # Quick training\\n            model.train()\\n            for epoch in range(epochs_per_architecture):\\n                for batch_idx, (data, target) in enumerate(train_loader):\\n                    if batch_idx > 20:  # Limit batches for speed\\n                        break\\n                    data, target = data.to(self.device), target.to(self.device)\\n                    optimizer.zero_grad()\\n                    output = model(data, architecture)\\n                    loss = criterion(output, target)\\n                    loss.backward()\\n                    optimizer.step()\\n            \\n            # Quick evaluation\\n            model.eval()\\n            correct = 0\\n            total = 0\\n            with torch.no_grad():\\n                for batch_idx, (data, target) in enumerate(test_loader):\\n                    if batch_idx > 10:  # Limit batches for speed\\n                        break\\n                    data, target = data.to(self.device), target.to(self.device)\\n                    output = model(data, architecture)\\n                    _, predicted = output.max(1)\\n                    total += target.size(0)\\n                    correct += predicted.eq(target).sum().item()\\n            \\n            return 100. * correct / total\\n        \\n        # Create small dataset for NAS demo\\n        transform = transforms.Compose([\\n            transforms.ToTensor(),\\n            transforms.Normalize((0.5,), (0.5,))\\n        ])\\n        \\n        print(\\\"ðŸ“¥ Loading small dataset for NAS demo...\\\")\\n        trainset = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform)\\n        testset = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform)\\n        \\n        # Use smaller subsets for speed\\n        train_subset = torch.utils.data.Subset(trainset, range(1000))\\n        test_subset = torch.utils.data.Subset(testset, range(200))\\n        \\n        train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\\n        test_loader = DataLoader(test_subset, batch_size=64, shuffle=False)\\n        \\n        # Search over architectures\\n        best_architecture = None\\n        best_accuracy = 0.0\\n        architecture_results = []\\n        \\n        print(f\\\"ðŸ” Searching over {search_space_size} architectures...\\\")\\n        \\n        for i in tqdm(range(search_space_size), desc=\\\"Architecture Search\\\"):\\n            # Random architecture: [layer1_choice, layer2_choice, layer3_choice]\\n            architecture = [random.randint(0, 2) for _ in range(3)]\\n            \\n            # Create and evaluate model\\n            model = NASModel().to(self.device)\\n            accuracy = evaluate_architecture(architecture, model, train_loader, test_loader)\\n            \\n            architecture_results.append((architecture, accuracy))\\n            \\n            if accuracy > best_accuracy:\\n                best_accuracy = accuracy\\n                best_architecture = architecture\\n        \\n        # Results\\n        print(f\\\"\\\\nâœ… Neural Architecture Search completed!\\\")\\n        print(f\\\"ðŸ† Best architecture: {best_architecture}\\\")\\n        print(f\\\"ðŸ“Š Best accuracy: {best_accuracy:.2f}%\\\")\\n        \\n        # Analyze results\\n        arch_choices = ['3x3 Conv', '5x5 Conv', '1x1 Conv']\\n        print(f\\\"\\\\nðŸ“Š Architecture breakdown:\\\")\\n        for i, choice in enumerate(best_architecture):\\n            print(f\\\"   Layer {i+1}: {arch_choices[choice]}\\\")\\n        \\n        return best_architecture, architecture_results\\n    \\n    def meta_learning_few_shot(self, n_way=5, k_shot=1, query_shots=15):\\n        \\\"\\\"\\\"Model-Agnostic Meta-Learning (MAML) for few-shot learning\\\"\\\"\\\"\\n        print(f\\\"ðŸ§  Meta-Learning: {n_way}-way {k_shot}-shot Learning\\\")\\n        print(\\\"=\\\" * 45)\\n        \\n        class SimpleMAMLModel(nn.Module):\\n            \\\"\\\"\\\"Simple model for MAML demonstration\\\"\\\"\\\"\\n            def __init__(self, input_size=84*84*3, hidden_size=128, output_size=5):\\n                super().__init__()\\n                self.net = nn.Sequential(\\n                    nn.Linear(input_size, hidden_size),\\n                    nn.ReLU(),\\n                    nn.Linear(hidden_size, hidden_size),\\n                    nn.ReLU(),\\n                    nn.Linear(hidden_size, output_size)\\n                )\\n                \\n            def forward(self, x):\\n                return self.net(x.view(x.size(0), -1))\\n        \\n        def create_few_shot_task(dataset, n_way, k_shot, query_shots):\\n            \\\"\\\"\\\"Create a few-shot learning task\\\"\\\"\\\"\\n            # Simulate few-shot task creation\\n            classes = random.sample(range(10), n_way)  # Select n_way classes\\n            \\n            support_data = []\\n            support_labels = []\\n            query_data = []\\n            query_labels = []\\n            \\n            for i, class_idx in enumerate(classes):\\n                # Simulate k-shot support set\\n                for _ in range(k_shot):\\n                    # Create random data (in practice, this would be real data)\\n                    data = torch.randn(3, 84, 84)\\n                    support_data.append(data)\\n                    support_labels.append(i)\\n                \\n                # Create query set\\n                for _ in range(query_shots):\\n                    data = torch.randn(3, 84, 84)\\n                    query_data.append(data)\\n                    query_labels.append(i)\\n            \\n            support_data = torch.stack(support_data)\\n            support_labels = torch.tensor(support_labels)\\n            query_data = torch.stack(query_data)\\n            query_labels = torch.tensor(query_labels)\\n            \\n            return (support_data, support_labels), (query_data, query_labels)\\n        \\n        def maml_inner_update(model, support_data, support_labels, lr_inner=0.01):\\n            \\\"\\\"\\\"Inner loop update for MAML\\\"\\\"\\\"\\n            # Create a copy of the model for inner updates\\n            model_copy = type(model)()\\n            model_copy.load_state_dict(model.state_dict())\\n            model_copy = model_copy.to(self.device)\\n            \\n            criterion = nn.CrossEntropyLoss()\\n            \\n            # Inner gradient update\\n            support_data = support_data.to(self.device)\\n            support_labels = support_labels.to(self.device)\\n            \\n            output = model_copy(support_data)\\n            loss = criterion(output, support_labels)\\n            \\n            # Compute gradients\\n            grads = torch.autograd.grad(loss, model_copy.parameters(), create_graph=True)\\n            \\n            # Manual parameter update\\n            for param, grad in zip(model_copy.parameters(), grads):\\n                param.data = param.data - lr_inner * grad\\n            \\n            return model_copy\\n        \\n        # Initialize meta-model\\n        meta_model = SimpleMAMLModel().to(self.device)\\n        meta_optimizer = optim.Adam(meta_model.parameters(), lr=0.001)\\n        criterion = nn.CrossEntropyLoss()\\n        \\n        print(f\\\"ðŸš€ Starting MAML training...\\\")\\n        \\n        # Meta-training loop\\n        n_meta_epochs = 20\\n        tasks_per_epoch = 10\\n        \\n        for epoch in range(n_meta_epochs):\\n            meta_loss = 0.0\\n            \\n            for task in range(tasks_per_epoch):\\n                # Sample a task\\n                (support_data, support_labels), (query_data, query_labels) = create_few_shot_task(\\n                    None, n_way, k_shot, query_shots\\n                )\\n                \\n                # Inner loop: adapt to support set\\n                adapted_model = maml_inner_update(meta_model, support_data, support_labels)\\n                \\n                # Outer loop: evaluate on query set\\n                query_data = query_data.to(self.device)\\n                query_labels = query_labels.to(self.device)\\n                \\n                query_output = adapted_model(query_data)\\n                task_loss = criterion(query_output, query_labels)\\n                \\n                meta_loss += task_loss\\n            \\n            # Meta-update\\n            meta_optimizer.zero_grad()\\n            meta_loss.backward()\\n            meta_optimizer.step()\\n            \\n            if (epoch + 1) % 5 == 0:\\n                print(f\\\"Meta-Epoch {epoch+1}: Meta-Loss = {meta_loss.item()/tasks_per_epoch:.4f}\\\")\\n        \\n        print(\\\"âœ… Meta-learning training completed!\\\")\\n        print(\\\"ðŸ’¡ Model can now quickly adapt to new tasks with few examples\\\")\\n        \\n        return meta_model\\n    \\n    def self_supervised_learning(self, train_loader, epochs=20):\\n        \\\"\\\"\\\"Self-supervised learning with SimCLR-style contrastive learning\\\"\\\"\\\"\\n        print(\\\"ðŸ”„ Self-Supervised Learning (Contrastive)\\\")\\n        print(\\\"=\\\" * 40)\\n        \\n        class ContrastiveAugmentation:\\n            \\\"\\\"\\\"Data augmentation for contrastive learning\\\"\\\"\\\"\\n            def __init__(self):\\n                self.transform = transforms.Compose([\\n                    transforms.RandomResizedCrop(32, scale=(0.8, 1.0)),\\n                    transforms.RandomHorizontalFlip(),\\n                    transforms.ColorJitter(0.4, 0.4, 0.4, 0.1),\\n                    transforms.RandomGrayscale(p=0.2),\\n                    transforms.ToTensor(),\\n                    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\\n                ])\\n            \\n            def __call__(self, x):\\n                return self.transform(x), self.transform(x)\\n        \\n        class SimCLRProjector(nn.Module):\\n            \\\"\\\"\\\"Projection head for SimCLR\\\"\\\"\\\"\\n            def __init__(self, input_dim=512, hidden_dim=512, output_dim=128):\\n                super().__init__()\\n                self.net = nn.Sequential(\\n                    nn.Linear(input_dim, hidden_dim),\\n                    nn.ReLU(inplace=True),\\n                    nn.Linear(hidden_dim, output_dim)\\n                )\\n                \\n            def forward(self, x):\\n                return self.net(x)\\n        \\n        class ContrastiveLoss(nn.Module):\\n            \\\"\\\"\\\"NT-Xent loss for contrastive learning\\\"\\\"\\\"\\n            def __init__(self, temperature=0.07):\\n                super().__init__()\\n                self.temperature = temperature\\n                \\n            def forward(self, z1, z2):\\n                batch_size = z1.size(0)\\n                \\n                # Normalize embeddings\\n                z1 = F.normalize(z1, dim=1)\\n                z2 = F.normalize(z2, dim=1)\\n                \\n                # Concatenate positive pairs\\n                representations = torch.cat([z1, z2], dim=0)\\n                \\n                # Compute similarity matrix\\n                similarity_matrix = torch.matmul(representations, representations.T)\\n                \\n                # Create labels for positive pairs\\n                labels = torch.cat([torch.arange(batch_size) + batch_size, \\n                                   torch.arange(batch_size)], dim=0)\\n                labels = labels.to(self.device)\\n                \\n                # Remove self-similarity\\n                mask = torch.eye(2 * batch_size, dtype=bool).to(self.device)\\n                similarity_matrix.masked_fill_(mask, -9e15)\\n                \\n                # Apply temperature\\n                similarity_matrix = similarity_matrix / self.temperature\\n                \\n                # Compute cross-entropy loss\\n                loss = F.cross_entropy(similarity_matrix, labels)\\n                \\n                return loss\\n        \\n        # Create encoder (ResNet backbone)\\n        from torchvision.models import resnet18\\n        encoder = resnet18(pretrained=False)\\n        encoder.fc = nn.Identity()  # Remove classification head\\n        encoder = encoder.to(self.device)\\n        \\n        # Add projection head\\n        projector = SimCLRProjector(512, 512, 128).to(self.device)\\n        \\n        # Combine encoder and projector\\n        model = nn.Sequential(encoder, projector)\\n        \\n        optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-6)\\n        criterion = ContrastiveLoss().to(self.device)\\n        \\n        print(f\\\"ðŸš€ Starting self-supervised training...\\\")\\n        \\n        # Create contrastive dataset\\n        augmentation = ContrastiveAugmentation()\\n        \\n        for epoch in range(epochs):\\n            model.train()\\n            total_loss = 0.0\\n            \\n            progress_bar = tqdm(train_loader, desc=f'SSL Epoch {epoch+1}/{epochs}')\\n            \\n            for batch_idx, (data, _) in enumerate(progress_bar):\\n                if batch_idx > 50:  # Limit for demo\\n                    break\\n                    \\n                # Create augmented pairs\\n                data1_list = []\\n                data2_list = []\\n                \\n                for img in data:\\n                    img_pil = transforms.ToPILImage()(img)\\n                    aug1, aug2 = augmentation(img_pil)\\n                    data1_list.append(aug1)\\n                    data2_list.append(aug2)\\n                \\n                data1 = torch.stack(data1_list).to(self.device)\\n                data2 = torch.stack(data2_list).to(self.device)\\n                \\n                optimizer.zero_grad()\\n                \\n                # Forward pass\\n                z1 = model(data1)\\n                z2 = model(data2)\\n                \\n                # Contrastive loss\\n                loss = criterion(z1, z2)\\n                \\n                loss.backward()\\n                optimizer.step()\\n                \\n                total_loss += loss.item()\\n                \\n                progress_bar.set_postfix({'Loss': f'{loss.item():.4f}'})\\n            \\n            avg_loss = total_loss / min(len(train_loader), 50)\\n            print(f'Epoch {epoch+1}: Average Loss = {avg_loss:.4f}')\\n        \\n        print(\\\"âœ… Self-supervised learning completed!\\\")\\n        print(\\\"ðŸ’¡ Learned representations can be fine-tuned for downstream tasks\\\")\\n        \\n        return model[0]  # Return encoder without projection head\\n    \\n    def distributed_training_setup(self):\\n        \\\"\\\"\\\"Setup for distributed training across multiple GPUs/nodes\\\"\\\"\\\"\\n        print(\\\"ðŸŒ Distributed Training Setup\\\")\\n        print(\\\"=\\\" * 28)\\n        \\n        if not torch.cuda.is_available():\\n            print(\\\"âŒ CUDA not available - distributed training requires GPUs\\\")\\n            return None\\n        \\n        if torch.cuda.device_count() < 2:\\n            print(\\\"âš ï¸  Only one GPU detected - simulating distributed setup\\\")\\n            print(\\\"ðŸ’¡ For real distributed training, use multiple GPUs or nodes\\\")\\n        \\n        # Distributed training simulation\\n        class DistributedTrainer:\\n            def __init__(self, model, rank=0, world_size=1):\\n                self.rank = rank\\n                self.world_size = world_size\\n                self.device = torch.device(f'cuda:{rank}' if torch.cuda.is_available() else 'cpu')\\n                \\n                # Wrap model with DDP (simulation)\\n                self.model = model.to(self.device)\\n                if world_size > 1 and torch.cuda.is_available():\\n                    self.model = nn.DataParallel(model)\\n                \\n            def train_step(self, data, target, optimizer, criterion):\\n                \\\"\\\"\\\"Single training step with gradient synchronization\\\"\\\"\\\"\\n                data, target = data.to(self.device), target.to(self.device)\\n                \\n                optimizer.zero_grad()\\n                output = self.model(data)\\n                loss = criterion(output, target)\\n                loss.backward()\\n                \\n                # In real DDP, gradients are automatically synchronized here\\n                optimizer.step()\\n                \\n                return loss.item()\\n            \\n            def save_checkpoint(self, epoch, optimizer, loss, filename):\\n                \\\"\\\"\\\"Save training checkpoint\\\"\\\"\\\"\\n                checkpoint = {\\n                    'epoch': epoch,\\n                    'model_state_dict': self.model.state_dict(),\\n                    'optimizer_state_dict': optimizer.state_dict(),\\n                    'loss': loss,\\n                    'rank': self.rank\\n                }\\n                torch.save(checkpoint, f'{filename}_rank{self.rank}.pth')\\n        \\n        print(\\\"âœ… Distributed training setup completed!\\\")\\n        print(\\\"ðŸ“Š Key components:\\\")\\n        print(\\\"   - Data Parallel / Distributed Data Parallel\\\")\\n        print(\\\"   - Gradient synchronization across workers\\\")\\n        print(\\\"   - Checkpoint saving and loading\\\")\\n        print(\\\"   - Learning rate scaling for large batch sizes\\\")\\n        \\n        return DistributedTrainer\\n    \\n    def advanced_optimization_techniques(self):\\n        \\\"\\\"\\\"Demonstrate advanced optimization techniques\\\"\\\"\\\"\\n        print(\\\"ðŸ”§ Advanced Optimization Techniques\\\")\\n        print(\\\"=\\\" * 35)\\n        \\n        class LookAhead(optim.Optimizer):\\n            \\\"\\\"\\\"LookAhead optimizer wrapper\\\"\\\"\\\"\\n            def __init__(self, base_optimizer, alpha=0.5, k=5):\\n                self.base_optimizer = base_optimizer\\n                self.alpha = alpha\\n                self.k = k\\n                self.param_groups = base_optimizer.param_groups\\n                self.state = base_optimizer.state\\n                self.slow_weights = {}\\n                \\n                for group in self.param_groups:\\n                    for p in group['params']:\\n                        self.slow_weights[p] = p.data.clone()\\n            \\n            def step(self, closure=None):\\n                loss = self.base_optimizer.step(closure)\\n                \\n                # Update slow weights every k steps\\n                if hasattr(self, 'step_count'):\\n                    self.step_count += 1\\n                else:\\n                    self.step_count = 1\\n                \\n                if self.step_count % self.k == 0:\\n                    for group in self.param_groups:\\n                        for p in group['params']:\\n                            slow_weight = self.slow_weights[p]\\n                            slow_weight.data += self.alpha * (p.data - slow_weight.data)\\n                            p.data = slow_weight.data.clone()\\n                \\n                return loss\\n        \\n        class SAM(optim.Optimizer):\\n            \\\"\\\"\\\"Sharpness-Aware Minimization optimizer\\\"\\\"\\\"\\n            def __init__(self, params, base_optimizer, rho=0.05, **kwargs):\\n                self.rho = rho\\n                self.base_optimizer = base_optimizer(params, **kwargs)\\n                self.param_groups = self.base_optimizer.param_groups\\n                \\n            def first_step(self, zero_grad=False):\\n                grad_norm = self._grad_norm()\\n                for group in self.param_groups:\\n                    scale = self.rho / (grad_norm + 1e-12)\\n                    for p in group['params']:\\n                        if p.grad is None:\\n                            continue\\n                        e_w = p.grad * scale.to(p)\\n                        p.add_(e_w)  # Climb to the local maximum\\n                        self.state[p]['e_w'] = e_w\\n                \\n                if zero_grad:\\n                    self.zero_grad()\\n            \\n            def second_step(self, zero_grad=False):\\n                for group in self.param_groups:\\n                    for p in group['params']:\\n                        if p.grad is None:\\n                            continue\\n                        p.sub_(self.state[p]['e_w'])  # Get back to the original point\\n                \\n                self.base_optimizer.step()\\n                \\n                if zero_grad:\\n                    self.zero_grad()\\n            \\n            def _grad_norm(self):\\n                shared_device = self.param_groups[0]['params'][0].device\\n                norm = torch.norm(\\n                    torch.stack([\\n                        p.grad.norm(dtype=torch.float32).to(shared_device)\\n                        for group in self.param_groups for p in group['params']\\n                        if p.grad is not None\\n                    ]),\\n                    dtype=torch.float32\\n                )\\n                return norm\\n        \\n        # Demonstrate custom learning rate scheduler\\n        class WarmupCosineScheduler:\\n            \\\"\\\"\\\"Warmup + Cosine Annealing scheduler\\\"\\\"\\\"\\n            def __init__(self, optimizer, warmup_epochs, total_epochs, base_lr, max_lr):\\n                self.optimizer = optimizer\\n                self.warmup_epochs = warmup_epochs\\n                self.total_epochs = total_epochs\\n                self.base_lr = base_lr\\n                self.max_lr = max_lr\\n                self.current_epoch = 0\\n            \\n            def step(self):\\n                if self.current_epoch < self.warmup_epochs:\\n                    # Linear warmup\\n                    lr = self.base_lr + (self.max_lr - self.base_lr) * self.current_epoch / self.warmup_epochs\\n                else:\\n                    # Cosine annealing\\n                    progress = (self.current_epoch - self.warmup_epochs) / (self.total_epochs - self.warmup_epochs)\\n                    lr = self.base_lr + (self.max_lr - self.base_lr) * 0.5 * (1 + np.cos(np.pi * progress))\\n                \\n                for param_group in self.optimizer.param_groups:\\n                    param_group['lr'] = lr\\n                \\n                self.current_epoch += 1\\n                return lr\\n        \\n        print(\\\"âœ… Advanced optimization techniques implemented:\\\")\\n        print(\\\"   ðŸ” LookAhead: Improves convergence stability\\\")\\n        print(\\\"   ðŸ“ˆ SAM: Finds flatter minima for better generalization\\\")\\n        print(\\\"   ðŸŒ¡ï¸  Warmup + Cosine: Better learning rate scheduling\\\")\\n        print(\\\"   âš¡ AdamW + Weight Decay: Improved regularization\\\")\\n        \\n        return LookAhead, SAM, WarmupCosineScheduler\n",
    "\n",
    "# Create instance\n",
    "super_advanced_trainer = SuperAdvancedTraining()\n",
    "print(\"ðŸ”¬ Super Advanced Training module initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55def6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸŽ¯ COMPREHENSIVE DEMONSTRATION: All Levels\n",
    "print(\"ðŸš€ RUNNING COMPREHENSIVE MODEL TRAINING DEMONSTRATIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Level 1: Easy Training Demo\n",
    "print(\"\\\\n\" + \"=\"*50)\n",
    "print(\"ðŸŒ± LEVEL 1: EASY TRAINING\")\n",
    "print(\"=\"*50)\n",
    "easy_trainer.create_simple_dataset()\n",
    "\n",
    "# Level 2: Intermediate Training (Quick Demo)\n",
    "print(\"\\\\n\" + \"=\"*50)\n",
    "print(\"ðŸš€ LEVEL 2: INTERMEDIATE TRAINING\")\n",
    "print(\"=\"*50)\n",
    "# Create smaller dataset for quick demo\n",
    "transform_quick = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "print(\"ðŸ“¥ Loading CIFAR-10 for quick intermediate demo...\")\n",
    "trainset_quick = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_quick)\n",
    "testset_quick = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_quick)\n",
    "\n",
    "# Use smaller subsets\n",
    "train_subset = torch.utils.data.Subset(trainset_quick, range(2000))\n",
    "test_subset = torch.utils.data.Subset(testset_quick, range(500))\n",
    "\n",
    "quick_train_loader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "quick_test_loader = DataLoader(test_subset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Create and train quick CNN\n",
    "print(\"ðŸ—ï¸  Creating quick CNN for demo...\")\n",
    "quick_cnn = intermediate_trainer.create_custom_cnn(num_classes=10)\n",
    "\n",
    "# Level 3: Advanced Training Demo\n",
    "print(\"\\\\n\" + \"=\"*50)\n",
    "print(\"âš¡ LEVEL 3: ADVANCED TRAINING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Demonstrate custom loss functions\n",
    "print(\"\\\\nðŸ”§ Custom Loss Functions Demo:\")\n",
    "FocalLoss, LabelSmoothingLoss, CutMixLoss = advanced_trainer.custom_loss_functions()\n",
    "\n",
    "# Quick mixed precision demo\n",
    "print(\"\\\\nðŸš€ Mixed Precision Training Demo (Quick):\")\n",
    "quick_model_copy = intermediate_trainer.create_custom_cnn(num_classes=10)\n",
    "advanced_trainer.mixed_precision_training(quick_model_copy, quick_train_loader, quick_test_loader, epochs=3)\n",
    "\n",
    "# Model compression demo\n",
    "print(\"\\\\nâœ‚ï¸  Model Compression Demo:\")\n",
    "compression_model = intermediate_trainer.create_custom_cnn(num_classes=10)\n",
    "compressed_model = advanced_trainer.model_compression_pruning(compression_model)\n",
    "\n",
    "# Level 4: Super Advanced Training Demo\n",
    "print(\"\\\\n\" + \"=\"*50)\n",
    "print(\"ðŸ”¬ LEVEL 4: SUPER ADVANCED TRAINING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Neural Architecture Search Demo (Quick)\n",
    "print(\"\\\\nðŸ” Neural Architecture Search Demo:\")\n",
    "best_arch, arch_results = super_advanced_trainer.neural_architecture_search(\n",
    "    search_space_size=10, epochs_per_architecture=2\n",
    ")\n",
    "\n",
    "# Meta-Learning Demo (Quick)\n",
    "print(\"\\\\nðŸ§  Meta-Learning Demo:\")\n",
    "meta_model = super_advanced_trainer.meta_learning_few_shot(n_way=3, k_shot=1, query_shots=5)\n",
    "\n",
    "# Self-Supervised Learning Demo (Quick)\n",
    "print(\"\\\\nðŸ”„ Self-Supervised Learning Demo:\")\n",
    "ssl_encoder = super_advanced_trainer.self_supervised_learning(quick_train_loader, epochs=3)\n",
    "\n",
    "# Distributed Training Setup\n",
    "print(\"\\\\nðŸŒ Distributed Training Setup:\")\n",
    "DistributedTrainer = super_advanced_trainer.distributed_training_setup()\n",
    "\n",
    "# Advanced Optimization\n",
    "print(\"\\\\nðŸ”§ Advanced Optimization Techniques:\")\n",
    "LookAhead, SAM, WarmupCosineScheduler = super_advanced_trainer.advanced_optimization_techniques()\n",
    "\n",
    "print(\"\\\\n\" + \"=\"*60)\n",
    "print(\"ðŸŽ‰ ALL DEMONSTRATIONS COMPLETED!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\\\nðŸ“š Summary of what you've learned:\")\n",
    "print(\"ðŸŒ± Easy: Basic neural networks and training loops\")\n",
    "print(\"ðŸš€ Intermediate: CNNs, real datasets, advanced training\")\n",
    "print(\"âš¡ Advanced: Multi-GPU, mixed precision, custom components\")\n",
    "print(\"ðŸ”¬ Super Advanced: NAS, meta-learning, self-supervised learning\")\n",
    "print(\"\\\\nðŸ’¡ You now have the complete toolkit for state-of-the-art model training!\")\n",
    "print(\"ðŸš€ Ready to tackle any computer vision challenge!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
